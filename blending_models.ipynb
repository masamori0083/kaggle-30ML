{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ded4a0b-d95a-443b-b254-d7e8d30f999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f3632-625d-4533-bcda-f9c8281f13bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "\n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.id.values.tolist()\n",
    "     \n",
    "\n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
    "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
    "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
    "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
    "    \n",
    "    model = XGBRegressor(random_state=fold,\n",
    "                         tree_method='gpu_hist',\n",
    "                         gpu_id=0,\n",
    "                         predictor=\"gpu_predictor\"\n",
    "                        )\n",
    "    \n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient='index').reset_index()\n",
    "final_valid_predictions.columns = ['id', 'pred_1']\n",
    "final_valid_predictions.to_csv('train_pred_1.csv', index=False)\n",
    "\n",
    "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = ['id', 'pred_1']\n",
    "sample_submission.to_csv('test_pred_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1871d9af-9cc6-4a22-a421-e4e23bff4f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial features\n",
    "df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "\n",
    "# polynomial features\n",
    "\n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "poly = preprocessing.PolynomialFeatures(degree=3, interaction_only=True, include_bias=False)\n",
    "train_poly = poly.fit_transform(df[numerical_cols])\n",
    "test_poly = poly.fit_transform(df_test[numerical_cols])\n",
    "\n",
    "df_poly = pd.DataFrame(train_poly, columns=[f\"poly_{i}\" for i in range(train_poly.shape[1])])\n",
    "df_test_poly = pd.DataFrame(test_poly, columns=[f\"poly_{i}\" for i in range(test_poly.shape[1])])\n",
    "\n",
    "df = pd.concat([df, df_poly], axis=1)\n",
    "df_test = pd.concat([df_test, df_test_poly], axis=1)\n",
    "\n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
    "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
    "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
    "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
    "    \n",
    "\n",
    "    \n",
    "    model = XGBRegressor(random_state=fold,\n",
    "                         tree_method='gpu_hist',\n",
    "                         gpu_id=0,\n",
    "                         predictor=\"gpu_predictor\",\n",
    "                        max_depth=2)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "    \n",
    "print(np.mean(scores), np.std(scores))\n",
    "\n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient='index').reset_index()\n",
    "final_valid_predictions.columns = ['id', 'pred_2']\n",
    "final_valid_predictions.to_csv('train_pred_2.csv', index=False)\n",
    "\n",
    "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = ['id', 'pred_2']\n",
    "sample_submission.to_csv('test_pred_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a943772-8054-4c1f-aa4a-ab6920348ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_encoding\n",
    "\n",
    "df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "\n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "object_cols = [col for col in useful_features if 'cat' in col]\n",
    "numerical_cols = [col for col in useful_features if col.startswith(\"cont\")]\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "\n",
    "# 各columns(catの英数字)毎にtargetの数値を平均して、特徴量に加える\n",
    "for col in object_cols:\n",
    "    temp_df = []\n",
    "    temp_test_feat = None\n",
    "    for fold in range(5):\n",
    "        xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "        xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "        # col(A, Bなど)毎にtarget(目的変数)の平均を出す\n",
    "        feat = xtrain.groupby(col)[\"target\"].agg('mean')\n",
    "        feat = feat.to_dict()\n",
    "        \n",
    "        #xvalidにtargetの平均columを加える\n",
    "        xvalid.loc[:, f\"tar_enc_{col}\"] = xvalid[col].map(feat)\n",
    "        temp_df.append(xvalid)\n",
    "        \n",
    "        # 値がtemp_test_featに入っていたら、targetの平均値を加える\n",
    "        if temp_test_feat is None:\n",
    "            temp_test_feat = df_test[col].map(feat)\n",
    "        else:\n",
    "            temp_test_feat += df_test[col].map(feat)\n",
    "            \n",
    "    #5回繰り返したので、5で割る\n",
    "    temp_test_feat /= 5\n",
    "    df_test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n",
    "    df = pd.concat(temp_df)\n",
    "    \n",
    "    \n",
    "useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n",
    "#object_colsの更新（target_encodingでcatの値を更新したため）\n",
    "object_cols = [col for col in useful_features if col.startswith('cat')]\n",
    "df_test = df_test[useful_features]\n",
    "    \n",
    "final_test_predictions = []\n",
    "final_valid_predictions = {}\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "    \n",
    "    valid_ids = xvalid.id.values.tolist()\n",
    "\n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    ordinal_encoder = preprocessing.OrdinalEncoder()\n",
    "    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n",
    "    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n",
    "    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n",
    "    \n",
    "\n",
    "    \n",
    "    model = XGBRegressor(random_state=fold,\n",
    "                         tree_method='gpu_hist',\n",
    "                         gpu_id=0,\n",
    "                         predictor=\"gpu_predictor\",\n",
    "                        max_depth=2)\n",
    "    model.fit(xtrain, ytrain)\n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_test_predictions.append(test_preds)\n",
    "    final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "    \n",
    "print(np.mean(scores), np.std(scores))\n",
    "    \n",
    "final_valid_predictions = pd.DataFrame.from_dict(final_valid_predictions, orient='index').reset_index()\n",
    "final_valid_predictions.columns = ['id', 'pred_3']\n",
    "final_valid_predictions.to_csv('train_pred_3.csv', index=False)\n",
    "\n",
    "sample_submission.target = np.mean(np.column_stack(final_test_predictions), axis=1)\n",
    "sample_submission.columns = ['id', 'pred_3']\n",
    "sample_submission.to_csv('test_pred_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5e186e-2bf9-423d-b592-e8b7302f12b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 各結果を格納したデータセットを結合して、一つのデータセットを作成する\n",
    "\n",
    "df = pd.read_csv(\"../input/30days-folds/train_folds.csv\")\n",
    "df_test = pd.read_csv(\"../input/30-days-of-ml/test.csv\")\n",
    "sample_submission = pd.read_csv(\"../input/30-days-of-ml/sample_submission.csv\")\n",
    "\n",
    "df1 = pd.read_csv('train_pred_1.csv')\n",
    "df2 = pd.read_csv('train_pred_2.csv')\n",
    "df3 = pd.read_csv('train_pred_3.csv')\n",
    "\n",
    "df_test1 = pd.read_csv('test_pred_1.csv')\n",
    "df_test2 = pd.read_csv('test_pred_2.csv')\n",
    "df_test3 = pd.read_csv('test_pred_3.csv')\n",
    "\n",
    "df = df.merge(df1, on='id', how='left')\n",
    "df = df.merge(df2, on='id', how='left')\n",
    "df = df.merge(df3, on='id', how='left')\n",
    "\n",
    "df_test = df_test.merge(df_test1, on='id', how='left')\n",
    "df_test = df_test.merge(df_test2, on='id', how='left')\n",
    "df_test = df_test.merge(df_test3, on='id', how='left')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0843e2-d8ec-4a3c-a0d4-8dca57a49b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending model and solution　単純に３で割る\n",
    "\n",
    "useful_features = ['pred_1', 'pred_2', 'pred_3']\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "         \n",
    "\n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    \n",
    "    preds_valid = (xvalid.pred_1 + xvalid.pred_2 + xvalid.pred_3) / 3\n",
    "    test_preds = (xtest.pred_1 + xtest.pred_2 + xtest.pred_3) / 3\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653d23fd-966b-4690-87d7-2d920289a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blending model with Linear Regression　モデルを用いて、さらに計算する\n",
    "\n",
    "useful_features = ['pred_1', 'pred_2', 'pred_3']\n",
    "df_test = df_test[useful_features]\n",
    "\n",
    "final_predictions = []\n",
    "scores = []\n",
    "for fold in range(5):\n",
    "    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n",
    "    xvalid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    xtest = df_test.copy()\n",
    "         \n",
    "\n",
    "    ytrain = xtrain.target\n",
    "    yvalid = xvalid.target\n",
    "    \n",
    "    xtrain = xtrain[useful_features]\n",
    "    xvalid = xvalid[useful_features]\n",
    "    \n",
    "    model = LinearRsgression()\n",
    "    model.fit(xtrain, ytrain)\n",
    "    \n",
    "    preds_valid = model.predict(xvalid)\n",
    "    test_preds = model.predict(xtest)\n",
    "    final_predictions.append(test_preds)\n",
    "    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n",
    "    print(fold, rmse)\n",
    "    print(model.coef_)\n",
    "    scores.append(rmse)\n",
    "\n",
    "print(np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa18501f-4b9e-4236-83c7-559e2e67772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.target = np.mean(np.column_stack(final_predictions), axis=1)\n",
    "sample_submission.to_csv('subission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
